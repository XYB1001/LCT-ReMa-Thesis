BASELINE

**************************************************
Results for SVM baseline with mixed data:
--------------------------------------------------
Accuracy: 0.6184135537018808
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.909695   0.819868   0.862449
a2           0.811825   0.703194   0.753615
b1           0.561232   0.545982   0.553502
b2           0.500291   0.491248   0.495728
c1           0.660013   0.694234   0.676691
c2           0.550723   0.537160   0.543857
--------------------------------------------------
Average (macro) F-score: 0.6476402123155153
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[ 1370    23    43    37   123    75]
 [   30  1277   103    78   226   102]
 [   19    59  2351   365  1026   486]
 [   18    46   354  2582  1493   763]
 [   40    99   867  1376 11341  2613]
 [   29    69   471   723  2974  4951]]

**************************************************




BASELINE + Noun-to-postag abstraction (word ngrams (1,3))

num features = 44156

**************************************************
Results for SVM baseline with noun abstraction:
--------------------------------------------------
Accuracy: 0.5425107507383037
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.724401   0.817711   0.768233
a2           0.764659   0.521930   0.620398
b1           0.452469   0.400941   0.425150
b2           0.484351   0.179434   0.261859
c1           0.556777   0.744815   0.637213
c2           0.478777   0.406195   0.439510
--------------------------------------------------
Average (macro) F-score: 0.5253936278394147
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[ 1422    18    26    10   193    70]
 [  143   952   182    32   380   135]
 [   88    93  1704   118  1806   441]
 [   71    63   558   944  2723   902]
 [  140    81   925   545 12209  2492]
 [   99    38   371   300  4617  3711]]

**************************************************

