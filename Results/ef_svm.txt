###### USING LEN-NORMALISED SAMPLES #################

noun postag abstraction

**************************************************
Results for SVM postag-transformed 1 - 3 grams:
--------------------------------------------------
Accuracy: 0.8712481168153899
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.909731   0.962737   0.935484
a2           0.903978   0.867105   0.885158
b1           0.837032   0.821088   0.828984
b2           0.889580   0.801682   0.843347
c1           0.840401   0.924905   0.880630
c2           0.864111   0.654354   0.744745
--------------------------------------------------
Average (macro) F-score: 0.8530578300780415
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[1421   16   11    3   24    1]
 [  75 1318   49   15   60    3]
 [  30   67 1207   53  107    6]
 [   5   29  101 1144  131   17]
 [  23   23   65   54 2180   12]
 [   8    5    9   17   92  248]]

**************************************************


noun postag abstraction + sent len

**************************************************
Results for SVM postag-transformed 1 - 3 grams + SentLen:
--------------------------------------------------
Accuracy: 0.8721752230849461
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.919231   0.956000   0.937255
a2           0.891503   0.885714   0.888599
b1           0.859674   0.827422   0.843239
b2           0.892628   0.790071   0.838224
c1           0.835712   0.930442   0.880536
c2           0.815331   0.609375   0.697466
--------------------------------------------------
Average (macro) F-score: 0.8475534666837132
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[1434   21   10    5   26    4]
 [  68 1364   41   13   54    0]
 [  20   84 1213   54   88    7]
 [   9   31   86 1114  153   17]
 [  20   27   50   40 2167   25]
 [   9    3   11   22  105  234]]

**************************************************

noun + verb abstraction

**************************************************
Results for SVM postag-transformed 1 - 3 grams
--------------------------------------------------
Accuracy: 0.8372928496928961
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.886658   0.952017   0.918176
a2           0.853389   0.833221   0.843184
b1           0.797151   0.769483   0.783072
b2           0.859339   0.756940   0.804896
c1           0.820155   0.905822   0.860862
c2           0.750000   0.575676   0.651376
--------------------------------------------------
Average (macro) F-score: 0.8102610704639536
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[1369   29   17    7   16    0]
 [  92 1234   70   17   68    0]
 [  34   94 1175   77  130   17]
 [   9   41  122 1118  164   23]
 [  26   35   70   58 2116   31]
 [  14   13   20   24   86  213]]

**************************************************


noun abstraction + freq info

**************************************************
Results for SVM postag-transformed 1 - 3 grams
--------------------------------------------------
Accuracy: 0.8765789778653378
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.928389   0.959683   0.943776
a2           0.892003   0.887755   0.889874
b1           0.852063   0.813859   0.832523
b2           0.895981   0.800704   0.845668
c1           0.843727   0.944094   0.891093
c2           0.852830   0.602667   0.706250
--------------------------------------------------
Average (macro) F-score: 0.851530568585783
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[1452   21    7    6   27    0]
 [  52 1305   56   16   39    2]
 [  26   64 1198   60  121    3]
 [  11   43   84 1137  129   16]
 [  14   21   45   35 2246   18]
 [   9    9   16   15  100  226]]

**************************************************

noun abstraction (uni, bi, tri) SPACY + freq info + char ngram (2,3) on unabstracted data

**************************************************
Results for SVM model:
--------------------------------------------------
Accuracy: 0.9207324139529494
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.958442   0.967869   0.963132
a2           0.925826   0.915944   0.920858
b1           0.903989   0.876147   0.889850
b2           0.911225   0.883986   0.897399
c1           0.911047   0.957808   0.933842
c2           0.907781   0.840000   0.872576
--------------------------------------------------
Average (macro) F-score: 0.9129430218759155
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[1476   19    7    9   11    3]
 [  39 1373   36   17   30    4]
 [  17   57 1337   56   56    3]
 [   4   19   65 1242   71    4]
 [   4   14   29   32 2202   18]
 [   0    1    5    7   47  315]]

**************************************************






############################################################################################

		Ealier results on non-len-normalised data

############################################################################################

Shape of Xtrain(pos): (21021, 32)
Shape of Ytrain: (21021,)


**************************************************
Results for SVM postag-transformed (uni):
--------------------------------------------------
Accuracy: 0.4432077625570776
--------------------------------------------------
Precision, recall and F-score per class:
/home/xiaoyu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
            Precision     Recall    F-score
a1           0.598337   0.956782   0.736250
a2           0.619308   0.225017   0.330097
b1           0.000000   0.000000   0.000000
b2           0.327493   0.944484   0.486348
c1           0.000000   0.000000   0.000000
c2           0.000000   0.000000   0.000000
--------------------------------------------------
Average (macro) F-score: 0.25878242962597675
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[1439   14    0   51    0    0]
 [ 658  340    0  512    1    0]
 [ 214  163    0 1130    0    0]
 [  59   19    0 1327    0    0]
 [  28   11    0  892    0    0]
 [   7    2    0  140    1    0]]

**************************************************

BELOW: POS uni + bi + trigrams

Shape of Xtrain(pos): (21021, 672)
Shape of Ytrain: (21021,)

**************************************************
Results for SVM postag-transformed (uni + bi + tri):
--------------------------------------------------
Accuracy: 0.5654965753424658
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.883427   0.836436   0.859290
a2           0.472951   0.763733   0.584156
b1           0.549258   0.270073   0.362100
b2           0.490899   0.614235   0.545684
c1           0.445880   0.296455   0.356129
c2           0.192308   0.033333   0.056818
--------------------------------------------------
Average (macro) F-score: 0.46069614372491585
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[1258  189   24   26    7    0]
 [ 110 1154  103  109   35    0]
 [  31  612  407  303  148    6]
 [  12  298  100  863  126    6]
 [  10  165   91  380  276    9]
 [   3   22   16   77   27    5]]

**************************************************

###################################################################
POS-tag transformation applied to nouns only
###################################################################

Shape of Xtrain(pos): (21021, 90)
Shape of Ytrain: (21021,)

**************************************************
Results for SVM postag-transformed (uni):
--------------------------------------------------
Accuracy: 0.3550228310502283
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.871728   0.688966   0.769646
a2           0.248880   0.946300   0.394109
b1           1.000000   0.002608   0.005202
b2           0.861111   0.022929   0.044669
c1           0.615385   0.008097   0.015984
c2           0.333333   0.006369   0.012500
--------------------------------------------------
Average (macro) F-score: 0.20701809935089893
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[ 999  451    0    0    0    0]
 [  81 1445    0    1    0    0]
 [  37 1489    4    2    0    2]
 [  11 1306    0   31    4    0]
 [  13  965    0    2    8    0]
 [   5  150    0    0    1    1]]

**************************************************

Shape of Xtrain(pos): (21021, 18849)
Shape of Ytrain: (21021,)

**************************************************
Results for SVM postag-transformed (uni + bi + tri):
--------------------------------------------------
Accuracy: 0.80550799086758
--------------------------------------------------
Precision, recall and F-score per class:
            Precision     Recall    F-score
a1           0.898884   0.944138   0.920955
a2           0.832177   0.863785   0.847686
b1           0.886607   0.647327   0.748304
b2           0.654680   0.915680   0.763491
c1           0.827114   0.673077   0.742188
c2           0.717647   0.388535   0.504132
--------------------------------------------------
Average (macro) F-score: 0.7544594020027305
--------------------------------------------------
Confusion matrix:
Labels: ['a1', 'a2', 'b1', 'b2', 'c1', 'c2']
[[1369   43   17   16    5    0]
 [  74 1319   50   58   22    4]
 [  50  140  993  292   51    8]
 [  11   32   32 1238   36    3]
 [  18   45   22  229  665    9]
 [   1    6    6   58   25   61]]

************************************************


